{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "# Data Preprocessing\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "# Draw Image / plot\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model\n",
    "\n",
    "## 여기서는 ImageGenerator를 통해서 데이터 증식을 활용해서 overfitting을 억제하는 것을 배운다. 다만 이렇게 생성된 데이터는 완전 새로운 데이터가 아니기 때문에 기존 정보의 재조합만 가능할 뿐이라 완전히 overfitting을 제거할 수 없다. 그렇기 때문에 dropdown layer를 fully connected classifer에 추가해 주었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Conv2D(32,(3,3), activation='relu', input_shape=(150,150,3)))\n",
    "model.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "model.add(layers.Conv2D(64,(3,3), activation='relu', input_shape=(150,150,3)))\n",
    "model.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "model.add(layers.Conv2D(128,(3,3), activation='relu', input_shape=(150,150,3)))\n",
    "model.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "model.add(layers.Conv2D(128,(3,3), activation='relu', input_shape=(150,150,3)))\n",
    "model.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 마지막 레이어의 활성함수가 sigmoid이기 때문에 \n",
    "# loss 함수를 binary crossentropy로 설정\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range = 20,\n",
    "                                   width_shift_range = 0.1,\n",
    "                                   height_shift_range = 0.1,\n",
    "                                   shear_range = 0.1,\n",
    "                                   zoom_range = 0.1,\n",
    "                                   horizontal_flip = True,\n",
    "                                   fill_mode = 'nearest')\n",
    "\n",
    "test_datagen  = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "dataset_dir = \"../keras_dataset/dogs_cats_small/\"\n",
    "train_dir = dataset_dir + \"train\"\n",
    "valid_dir = dataset_dir + \"validation\"\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(150,150),\n",
    "                                                    batch_size=32, class_mode='binary')\n",
    "validation_generator = test_datagen.flow_from_directory(valid_dir, target_size=(150,150),\n",
    "                                                    batch_size=32, class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 33s 334ms/step - loss: 0.6893 - acc: 0.5375 - val_loss: 0.6812 - val_acc: 0.5495\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 29s 285ms/step - loss: 0.6616 - acc: 0.5931 - val_loss: 0.6396 - val_acc: 0.6308\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 25s 253ms/step - loss: 0.6275 - acc: 0.6522 - val_loss: 0.6253 - val_acc: 0.6199\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 24s 242ms/step - loss: 0.6059 - acc: 0.6681 - val_loss: 0.6412 - val_acc: 0.6327\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 27s 273ms/step - loss: 0.5847 - acc: 0.6962 - val_loss: 0.5722 - val_acc: 0.6878\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 24s 245ms/step - loss: 0.5673 - acc: 0.7050 - val_loss: 0.5985 - val_acc: 0.6823\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 24s 241ms/step - loss: 0.5633 - acc: 0.7144 - val_loss: 0.5479 - val_acc: 0.7164\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 24s 244ms/step - loss: 0.5444 - acc: 0.7241 - val_loss: 0.5556 - val_acc: 0.7017\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 24s 237ms/step - loss: 0.5409 - acc: 0.7294 - val_loss: 0.5411 - val_acc: 0.7159\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 27s 271ms/step - loss: 0.5306 - acc: 0.7347 - val_loss: 0.5129 - val_acc: 0.7506\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.5184 - acc: 0.7400 - val_loss: 0.5571 - val_acc: 0.7216\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 28s 281ms/step - loss: 0.5142 - acc: 0.7419 - val_loss: 0.4997 - val_acc: 0.7602\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 26s 255ms/step - loss: 0.5005 - acc: 0.7531 - val_loss: 0.5207 - val_acc: 0.7629\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 27s 267ms/step - loss: 0.4991 - acc: 0.7528 - val_loss: 0.4907 - val_acc: 0.7621\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.4947 - acc: 0.7666 - val_loss: 0.5089 - val_acc: 0.7519\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 23s 235ms/step - loss: 0.4827 - acc: 0.7647 - val_loss: 0.5057 - val_acc: 0.7732\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.4639 - acc: 0.7872 - val_loss: 0.5077 - val_acc: 0.7437\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 26s 265ms/step - loss: 0.4696 - acc: 0.7678 - val_loss: 0.4792 - val_acc: 0.7732\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 25s 250ms/step - loss: 0.4549 - acc: 0.7897 - val_loss: 0.5202 - val_acc: 0.7602\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 26s 258ms/step - loss: 0.4457 - acc: 0.7947 - val_loss: 0.5385 - val_acc: 0.7423\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 28s 276ms/step - loss: 0.4558 - acc: 0.7897 - val_loss: 0.4618 - val_acc: 0.7957\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.4416 - acc: 0.7850 - val_loss: 0.4734 - val_acc: 0.7874\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 26s 262ms/step - loss: 0.4316 - acc: 0.8003 - val_loss: 0.5293 - val_acc: 0.7557\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 26s 256ms/step - loss: 0.4267 - acc: 0.8013 - val_loss: 0.4410 - val_acc: 0.7945\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.4362 - acc: 0.7941 - val_loss: 0.4520 - val_acc: 0.7977\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 27s 273ms/step - loss: 0.4093 - acc: 0.8144 - val_loss: 0.5240 - val_acc: 0.7538\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.4149 - acc: 0.8100 - val_loss: 0.4622 - val_acc: 0.7854\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 27s 266ms/step - loss: 0.4013 - acc: 0.8125 - val_loss: 0.4899 - val_acc: 0.7703\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 25s 249ms/step - loss: 0.3958 - acc: 0.8191 - val_loss: 0.5110 - val_acc: 0.7577\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 26s 257ms/step - loss: 0.3968 - acc: 0.8219 - val_loss: 0.4469 - val_acc: 0.7925\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 26s 260ms/step - loss: 0.3889 - acc: 0.8216 - val_loss: 0.4793 - val_acc: 0.7726\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 26s 261ms/step - loss: 0.3818 - acc: 0.8312 - val_loss: 0.4611 - val_acc: 0.8022\n",
      "Epoch 33/100\n",
      " 49/100 [=============>................] - ETA: 9s - loss: 0.4053 - acc: 0.8068"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=100,\n",
    "                              epochs=100, # it is increased than previous codes\n",
    "                              validation_data=validation_generator,\n",
    "                              validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"cats_and_dogs_small_2.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "handy_env",
   "language": "python",
   "name": "handy_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
